This issue decomposition maximizes parallelism by organizing work into 4 natural layers with minimal dependencies. Layer 0 (foundations) has 8 parallel issues that can start immediately: value-copy-trait, 4 benchmark suites (lexer/parser/compiler/vm), cpython-pure-execution-benchmark, and allocation-profiling-test. These provide the infrastructure needed for performance validation. Layer 1 (core VM) builds on value-copy-trait to implement vm-register-bitmap (the critical 85-90% bottleneck). Layer 2 extends Layer 1 with variable-name-interning, register-state-optimization, and smallstring-stdout-optimization, applied sequentially to avoid conflicts. Layer 3 validates everything with integration-verification (early smoke test) followed by performance-validation (AC1-AC6 compliance). The critical path length is 6 issues (value-copy → vm-register-bitmap → variable-name-interning → register-state-optimization → smallstring-stdout-optimization → integration-verification → performance-validation), but 8 issues can run in parallel initially. Every PRD acceptance criterion maps to specific issues: AC1 to vm-register-bitmap+performance-validation, AC2 to allocation-profiling-test+all optimization issues, AC3 to 4 benchmark issues, AC4 to performance-validation, AC5 to integration-verification, AC6 to cpython-comparison-script+cpython-pure-execution-benchmark. File metadata tracks touched files for merger agent conflict resolution. Testing strategies specify exact test files, frameworks (Criterion for benchmarks, cargo test for unit tests, dhat for allocation profiling), and AC mappings. Each issue is atomic (one focused session of work) with clear provides/depends_on for recovery. The architecture document is the source of truth for all implementation details - issues reference it but don't duplicate code.